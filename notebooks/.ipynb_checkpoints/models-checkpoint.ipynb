{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb064b4c-18ee-40f2-88fe-3295e63037a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vincent ho\\appdata\\roaming\\python\\python313\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\vincent ho\\appdata\\roaming\\python\\python313\\site-packages (2.2.3)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vincent ho\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vincent ho\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vincent ho\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vincent ho\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vincent ho\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vincent ho\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vincent ho\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vincent ho\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 11.0/124.9 MB 59.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 25.2/124.9 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 39.3/124.9 MB 66.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 54.5/124.9 MB 67.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 69.7/124.9 MB 68.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 84.4/124.9 MB 68.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 99.4/124.9 MB 68.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 112.5/124.9 MB 69.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 67.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 67.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 56.1 MB/s eta 0:00:00\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 49.9 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost, lightgbm\n",
      "Successfully installed lightgbm-4.6.0 xgboost-2.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pandas xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfe76a93-6d57-42d4-806a-8059f19fb212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6487f025-8cec-429a-a45f-a8e8d3b479bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../dataset/dataset.csv')\n",
    "\n",
    "for column in dataset.columns:\n",
    "    dataset = dataset.dropna(subset = [column])\n",
    "\n",
    "dataset['Risk_Level_Binary'] = dataset['Risk Level'].map({'High': 1, 'Low': 0})\n",
    "y = dataset['Risk_Level_Binary']\n",
    "dataset = dataset.drop(['Risk Level', 'Risk_Level_Binary'], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "febf9d81-eb06-41a5-8210-2e8f32ea5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y, test_size = .2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad1a019d-2bbd-4075-895f-2c89fcd0097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.9786, Precision: 0.9655, Recall: 0.9767, F1: 0.9711\n",
      "--------------------------------------------------\n",
      "Model: KNN\n",
      "Accuracy: 0.9744, Precision: 0.9545, Recall: 0.9767, F1: 0.9655\n",
      "--------------------------------------------------\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.9744, Precision: 0.9651, Recall: 0.9651, F1: 0.9651\n",
      "--------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9872, Precision: 0.9770, Recall: 0.9884, F1: 0.9827\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent Ho\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MLP\n",
      "Accuracy: 0.9786, Precision: 0.9655, Recall: 0.9767, F1: 0.9711\n",
      "--------------------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.9957, Precision: 0.9885, Recall: 1.0000, F1: 0.9942\n",
      "--------------------------------------------------\n",
      "Model: XGBoost\n",
      "Accuracy: 0.9915, Precision: 0.9884, Recall: 0.9884, F1: 0.9884\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 378, number of negative: 554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 271\n",
      "[LightGBM] [Info] Number of data points in the train set: 932, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.405579 -> initscore=-0.382270\n",
      "[LightGBM] [Info] Start training from score -0.382270\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model: LightGBM\n",
      "Accuracy: 0.9957, Precision: 0.9885, Recall: 1.0000, F1: 0.9942\n",
      "--------------------------------------------------\n",
      "Model: SVC\n",
      "Accuracy: 0.9744, Precision: 0.9545, Recall: 0.9767, F1: 0.9655\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent Ho\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'MLP': MLPClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier(),\n",
    "    'LightGBM': lgb.LGBMClassifier(),\n",
    "    'SVC': SVC(),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "    }\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44df37-38e1-4999-a5f7-412f90e7ea1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
